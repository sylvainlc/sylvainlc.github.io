<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="theme" content="hugo-academic">
  <meta name="generator" content="Hugo 0.52" />
  <meta name="author" content="Sylvain Le Corff">

  
  
  
  
  <meta name="description" content="Professor">

  
  <link rel="alternate" hreflang="en-us" href="/publication/">

  


  

  
  
  <meta name="theme-color" content="#0095eb">
  
  
  
  
    
  
  
  
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha512-6MXa8B6uaO18Hid6blRMetEIoPqHf7Ux1tnyIQdpt9qI5OACx7C+O3IVTr98vwGnlcg0LOLa02i9Y1HpVhlfiw==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha512-SfTiTlX6kk+qitfevl/7LibUOeJWlt9rbyDn92a1DqWOw9vWG2MFoays0sgObmWazO5BQPiFucnnEAjpAB+/Sw==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">
  
  
  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Montserrat:400,700%7cRoboto:400,400italic,700%7cRoboto&#43;Mono">
  
  <link rel="stylesheet" href="/styles.css">
  

  
  
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-131234483-1', 'auto');
      
      ga('require', 'eventTracker');
      ga('require', 'outboundLinkTracker');
      ga('require', 'urlChangeTracker');
      ga('send', 'pageview');
    </script>
    <script async src="//www.google-analytics.com/analytics.js"></script>
    
    <script async src="https://cdnjs.cloudflare.com/ajax/libs/autotrack/2.4.1/autotrack.js" integrity="sha512-HUmooslVKj4m6OBu0OgzjXXr+QuFYy/k7eLI5jdeEy/F4RSgMn6XRWRGkFi5IFaFgy7uFTkegp3Z0XnJf3Jq+g==" crossorigin="anonymous"></script>
    
  
  

  
  <link rel="alternate" href="/publication/index.xml" type="application/rss+xml" title="Sylvain Le Corff">
  <link rel="feed" href="/publication/index.xml" type="application/rss+xml" title="Sylvain Le Corff">
  

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="/publication/">

  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="og:site_name" content="Sylvain Le Corff">
  <meta property="og:url" content="/publication/">
  <meta property="og:title" content="Publications | Sylvain Le Corff">
  <meta property="og:description" content="Professor">
  <meta property="og:locale" content="en-us">
  
  <meta property="og:updated_time" content="2017-01-01T00:00:00&#43;01:00">
  

  

  

  <title>Publications | Sylvain Le Corff</title>

</head>
<body id="top" data-spy="scroll" data-target="#toc" data-offset="71" >

<nav class="navbar navbar-default navbar-fixed-top" id="navbar-main">
  <div class="container">

    
    <div class="navbar-header">
      
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
              data-target=".navbar-collapse" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      
      <a class="navbar-brand" href="/">Sylvain Le Corff</a>
    </div>

    
    <div class="collapse navbar-collapse">

      
      
      <ul class="nav navbar-nav navbar-right">
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#about">
            
            <span>Home</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#projects">
            
            <span>Research activities &amp; duties</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#publications">
            
            <span>Publications</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#talks">
            
            <span>Talks</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#teaching">
            
            <span>Teaching</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#contact">
            
            <span>Contact</span>
            
          </a>
        </li>

        
        
      

      
      </ul>

    </div>
  </div>
</nav>





<div class="container">
  <div class="row">
    <div class="col-md-12">
      <h1>Publications</h1>

      

      
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      

      <p>
        Filter by type:

        <select class="pub-filters pubtype-select" data-filter-group="pubtype">
          <option value="*">All</option>
          
          <option value=".pubtype-1">
            Conference paper
          </option>
          
          <option value=".pubtype-2">
            Journal article
          </option>
          
        </select>

        <select class="pub-filters" data-filter-group="year">
          <option value="*">All</option>
          
          
          
          <option value=".year-2020">
            2020
          </option>
          
          <option value=".year-2019">
            2019
          </option>
          
          <option value=".year-2018">
            2018
          </option>
          
          <option value=".year-2017">
            2017
          </option>
          
          <option value=".year-2015">
            2015
          </option>
          
          <option value=".year-2014">
            2014
          </option>
          
          <option value=".year-2013">
            2013
          </option>
          
          <option value=".year-2011">
            2011
          </option>
          
          
        </select>
      </p>

      <div id="container-publications">
        

        
          
        

        <div class="grid-sizer col-md-12 isotope-item pubtype-2 year-2020">
          
            <div class="pub-list-item card-simple" itemscope itemtype="http://schema.org/CreativeWork">

  
  

  <h3 class="article-title" itemprop="name">
    <a href="/publication/diel_lecorff_lerasle_2020/" itemprop="url">Learning the distribution of latent variables in paired comparison models</a>
  </h3>

  <div class="pub-abstract" itemprop="text">
    
    Paired comparison data considered in this paper originate from the comparison of a large number N of individuals in couples.  The dataset is a collection of results of contests between two individuals when each of them has faced n opponents, where n is much larger than N.  Individual are represented by independent and identically distributed random parameters characterizing their abilities. The paper studies the maximum likelihood estimator of the parameters distribution.  The analysis relies on the construction of a graphical model encoding conditional dependencies of the observations which are the outcomes of the first n contests each individual is involved in. This graphical model allows to prove geometric loss of memory properties and deduce the asymptotic behavior of the likelihood function. This paper sets the focus on graphical models obtained from round-robin scheduling of these contests. Following a classical construction in learning theory, the asymptotic likelihood is used to measure performance of the maximum likelihood estimator. Risk bounds for this estimator are finally obtained by sub-Gaussian deviation results for Markov chains applied to the graphical model..
    
  </div>

  <div class="pub-authors" itemprop="author">
    
    Diel, R., Le Corff, S., Lerasle, M.
    
  </div>

  <div class="pub-publication">
    
    Bernoulli, volume 26, number 4, p. 2670-2698,
    
    2020
  </div>

  <div class="pub-links">
    



<a class="btn btn-primary btn-outline btn-xs" href="https://www.researchgate.net/publication/318222115_Learning_latent_structure_of_large_random_graphs" target="_blank" rel="noopener">
  Preprint
</a>














<a class="btn btn-primary btn-outline btn-xs" href="https://projecteuclid.org/euclid.bj/1598493627" target="_blank" rel="noopener">
  Source Document
</a>



  </div>

</div>

          
        </div>

        

        
          
        

        <div class="grid-sizer col-md-12 isotope-item pubtype-1 year-2020">
          
            <div class="pub-list-item card-simple" itemscope itemtype="http://schema.org/CreativeWork">

  
  

  <h3 class="article-title" itemprop="name">
    <a href="/publication/martin_etal_2020/" itemprop="url">The Monte Carlo Transformer: a stochastic self-attention model for sequence prediction</a>
  </h3>

  <div class="pub-abstract" itemprop="text">
    
    This paper introduces the Sequential Monte Carlo Transformer, an original approach that naturally captures the observations distribution in a recurrent architecture. The keys, queries, values and attention vectors of the network are considered as the unobserved stochastic states of its hidden structure. This generative model is such that at each time step the received observation is a random function of these past states in a given attention window. In this general state-space setting, we use Sequential Monte Carlo methods to approximate the posterior distributions of the states given the observations, and then to estimate the gradient of the log-likelihood. We thus propose a generative model providing a predictive distribution, instead of a single-point estimate.
    
  </div>

  <div class="pub-authors" itemprop="author">
    
    Martin, A., Ollion, C., Strub, F., Le Corff, S., Pietquin, O.
    
  </div>

  <div class="pub-publication">
    
    Submitted,
    
    2020
  </div>

  <div class="pub-links">
    



<a class="btn btn-primary btn-outline btn-xs" href="https://www.researchgate.net/publication/343063352_The_Monte_Carlo_Transformer_a_stochastic_self-attention_model_for_sequence_prediction" target="_blank" rel="noopener">
  Preprint
</a>
















  </div>

</div>

          
        </div>

        

        
          
        

        <div class="grid-sizer col-md-12 isotope-item pubtype-1 year-2020">
          
            <div class="pub-list-item card-simple" itemscope itemtype="http://schema.org/CreativeWork">

  
  

  <h3 class="article-title" itemprop="name">
    <a href="/publication/cohen_etal_2020/" itemprop="url">End-to-end deep metamodeling to calibrate and optimize energy loads</a>
  </h3>

  <div class="pub-abstract" itemprop="text">
    
    In this paper, we propose a new end-to-end methodology to optimize the energy performance and the comfort, air quality and hygiene of large buildings. A metamodel based on a Transformer network is introduced and trained using a dataset sampled with a simulation program. Then, a few physical parameters and the building management system settings of this metamodel are calibrated using the CMA-ES optimization algorithm and real data obtained from sensors. Finally, the optimal settings to minimize the energy loads while maintaining a target thermal comfort and air quality are obtained using a multi-objective optimization procedure. The numerical experiments illustrate how this metamodel ensures a significant gain in energy efficiency while being computationally much more appealing than models requiring a huge number of physical parameters to be estimated.
    
  </div>

  <div class="pub-authors" itemprop="author">
    
    Cohen, M., Charbit, M., Le Corff, S., Preda, M., Noziere, G.
    
  </div>

  <div class="pub-publication">
    
    Submitted,
    
    2020
  </div>

  <div class="pub-links">
    



<a class="btn btn-primary btn-outline btn-xs" href="https://www.researchgate.net/publication/342377478_End-to-end_deep_metamodeling_to_calibrate_and_optimize_energy_loads" target="_blank" rel="noopener">
  Preprint
</a>
















  </div>

</div>

          
        </div>

        

        
          
        

        <div class="grid-sizer col-md-12 isotope-item pubtype-2 year-2020">
          
            <div class="pub-list-item card-simple" itemscope itemtype="http://schema.org/CreativeWork">

  
  

  <h3 class="article-title" itemprop="name">
    <a href="/publication/gassiat_lehericy_lecorff_2020/" itemprop="url">Deconvolution with unknown noise distribution is possible for multivariate signals</a>
  </h3>

  <div class="pub-abstract" itemprop="text">
    
    This paper considers the deconvolution problem in the case where the target signal is multidimensional and no information is known about the noise distribution. More precisely, no assumption is made on the noise distribution and no samples are available to estimate it: the deconvolution problem is solved based only on the corrupted signal observations. We establish the identifiability of the model up to translation when the signal has a Laplace transform with an exponential growth smaller than 2 and when it can be decomposed into two dependent components. Then, we propose an estimator of the probability density function of the signal without any assumption on the noise distribution. As this estimator depends of the lightness of the tail of the signal distribution which is usually unknown, a model selection procedure is proposed to obtain an adaptive estimator in this parameter with the same rate of convergence as the estimator with a known tail parameter. Finally, we establish a lower bound on the minimax rate of convergence that matches the upper bound.
    
  </div>

  <div class="pub-authors" itemprop="author">
    
    Gassiat, E., Le Corff, S., Lehericy, L.
    
  </div>

  <div class="pub-publication">
    
    Submitted,
    
    2020
  </div>

  <div class="pub-links">
    



<a class="btn btn-primary btn-outline btn-xs" href="https://www.researchgate.net/publication/342464541_Deconvolution_with_unknown_noise_distribution_is_possible_for_multivariate_signals" target="_blank" rel="noopener">
  Preprint
</a>
















  </div>

</div>

          
        </div>

        

        
          
        

        <div class="grid-sizer col-md-12 isotope-item pubtype-1 year-2020">
          
            <div class="pub-list-item card-simple" itemscope itemtype="http://schema.org/CreativeWork">

  
  

  <h3 class="article-title" itemprop="name">
    <a href="/publication/etienne_gloaguen_lecorff_olsson2020/" itemprop="url">Backward importance sampling for partially observed diffusion processes</a>
  </h3>

  <div class="pub-abstract" itemprop="text">
    
    This paper proposes a new Sequential Monte Carlo algorithm to perform maximum likelihood estimation in partially observed diffusion processes. Training such generative models and obtaining low variance estimators of the posterior distributions of the latent states given the observations is challenging as the transition densities of the latent states cannot be evaluated pointwise. In this paper, a backward importance sampling step is introduced to estimate such posterior distributions instead of the usual acceptance-rejection approach. This allows to use unbiased estimates of the unknown transition densities available under mild assumptions for multivariate stochastic differential equations while acceptance-rejection based methods require strong conditions to obtain upper-bounded estimators. The performance of this estimator is assessed in the case of a partially observed stochastic Lotka-Volterra model.
    
  </div>

  <div class="pub-authors" itemprop="author">
    
    Etienne, M.-P., Gloaguen, P., Le Corff, S., Olsson, J.
    
  </div>

  <div class="pub-publication">
    
    Submitted,
    
    2020
  </div>

  <div class="pub-links">
    



<a class="btn btn-primary btn-outline btn-xs" href="https://www.researchgate.net/publication/339252227_Backward_importance_sampling_for_partially_observed_diffusion_processes" target="_blank" rel="noopener">
  Preprint
</a>
















  </div>

</div>

          
        </div>

        

        
          
        

        <div class="grid-sizer col-md-12 isotope-item pubtype-2 year-2020">
          
            <div class="pub-list-item card-simple" itemscope itemtype="http://schema.org/CreativeWork">

  
  

  <h3 class="article-title" itemprop="name">
    <a href="/publication/gassiat_lehericy_lecorff_2019/" itemprop="url">Identifiability and consistent estimation of nonparametric translation hidden Markov models with general state space</a>
  </h3>

  <div class="pub-abstract" itemprop="text">
    
    In this paper, we consider partially observed dynamical systems where the observations are given as the sum of latent variables lying in a general state space and some independent noise with unknown distribution. In the case of dependent latent variables such as Markov chains, it is shown that this fully nonparametric model is identifiable with respect to both the distribution of the latent variables and the distribution of the noise, under mostly a light tail assumption on the latent variables. Two nonparametric estimation methods are proposed and we prove that the corresponding estimators are consistent for the weak convergence topology. These results are illustrated with numerical experiments.
    
  </div>

  <div class="pub-authors" itemprop="author">
    
    Gassiat, E., Le Corff, S., Lehericy, L.
    
  </div>

  <div class="pub-publication">
    
    The Journal of Machine Learning Research (JMLR), (115):1-40, 2020,
    
    2020
  </div>

  <div class="pub-links">
    



<a class="btn btn-primary btn-outline btn-xs" href="https://www.researchgate.net/publication/342877717_Identifiability_and_Consistent_Estimation_of_Nonparametric_Translation_Hidden_Markov_Models_with_General_State_Space" target="_blank" rel="noopener">
  Preprint
</a>


<a class="btn btn-primary btn-outline btn-xs" href="http://www.jmlr.org/papers/volume21/19-802/19-802.pdf" target="_blank" rel="noopener">
  PDF
</a>













<a class="btn btn-primary btn-outline btn-xs" href="http://www.jmlr.org/papers/v21/" target="_blank" rel="noopener">
  Source Document
</a>



  </div>

</div>

          
        </div>

        

        
          
        

        <div class="grid-sizer col-md-12 isotope-item pubtype-2 year-2019">
          
            <div class="pub-list-item card-simple" itemscope itemtype="http://schema.org/CreativeWork">

  
  

  <h3 class="article-title" itemprop="name">
    <a href="/publication/gloaguen_lecorff_olsson2019/" itemprop="url">Online pseudo Marginal Sequential Monte Carlo smoother for general state spaces. Application to recursive maximum likelihood estimation of stochastic differential equations</a>
  </h3>

  <div class="pub-abstract" itemprop="text">
    
    This paper focuses on the estimation of smoothing distributions in general state space models where the transition density of the hidden Markov chain or the conditional likelihood of the observations given the latent state cannot be evaluated pointwise. The consistency and asymptotic normality of a pseudo marginal online algorithm to estimate smoothed expectations of additive functionals when these quantities are replaced by unbiased estimators are established. A recursive maximum likelihood estimation procedure is also introduced by combining this online algorithm with an estimation of the gradient of the filtering distributions, also known as the tangent filters, when the model is driven by unknown parameters. The performance of this estimator is assessed in the case of a partially observed stochastic differential equation.
    
  </div>

  <div class="pub-authors" itemprop="author">
    
    Gloaguen, P., Le Corff, S., Olsson, J.
    
  </div>

  <div class="pub-publication">
    
    Submitted,
    
    2019
  </div>

  <div class="pub-links">
    



<a class="btn btn-primary btn-outline btn-xs" href="https://www.researchgate.net/publication/335290600_Online_pseudo_Marginal_Sequential_Monte_Carlo_smoother_for_general_state_spaces_Application_to_recursive_maximum_likelihood_estimation_of_stochastic_differential_equations" target="_blank" rel="noopener">
  Preprint
</a>
















  </div>

</div>

          
        </div>

        

        
          
        

        <div class="grid-sizer col-md-12 isotope-item pubtype-2 year-2018">
          
            <div class="pub-list-item card-simple" itemscope itemtype="http://schema.org/CreativeWork">

  
  

  <h3 class="article-title" itemprop="name">
    <a href="/publication/lecorff_lerasle_vernet_2018/" itemprop="url">A Bayesian nonparametric approach for generalized Bradley-Terry models in random environment</a>
  </h3>

  <div class="pub-abstract" itemprop="text">
    
    This paper deals with the estimation of the unknown distribution of hidden random variables from the observation of pairwise comparisons between these variables. This problem is inspired by recent developments on Bradley-Terry models in random environment since this framework happens to be relevant to predict for instance the issue of a championship from the observation of a few contests per team. This paper provides three contributions on a Bayesian nonparametric approach to solve this problem. First, we establish contraction rates of the posterior distribution. We also propose a Markov Chain Monte Carlo  algorithm to approximately sample from this posterior distribution inspired from a recent Bayesian nonparametric method for hidden Markov models. Finally, the performance of this algorithm are appreciated by comparing predictions on the issue of a championship based on the actual values of the teams and those obtained by sampling from the estimated posterior distribution.
    
  </div>

  <div class="pub-authors" itemprop="author">
    
    Le Corff, S., Lerasle, M., Vernet, E.
    
  </div>

  <div class="pub-publication">
    
    Submitted,
    
    2018
  </div>

  <div class="pub-links">
    



<a class="btn btn-primary btn-outline btn-xs" href="https://www.researchgate.net/publication/327236987_A_Bayesian_nonparametric_approach_for_generalized_Bradley-Terry_models_in_random_environment" target="_blank" rel="noopener">
  Preprint
</a>
















  </div>

</div>

          
        </div>

        

        
          
        

        <div class="grid-sizer col-md-12 isotope-item pubtype-1 year-2018">
          
            <div class="pub-list-item card-simple" itemscope itemtype="http://schema.org/CreativeWork">

  
  

  <h3 class="article-title" itemprop="name">
    <a href="/publication/lecorff_charbit_champagne_noziere_moulines_2018/" itemprop="url">Optimizing thermal comfort and energy consumption in a large building without renovation work</a>
  </h3>

  <div class="pub-abstract" itemprop="text">
    
    This paper proposes a new methodology to reduce energy consumptions in large buildings while simultaneously optimizing thermal comfort. The model designed with an energy simulation program is calibrated by the Covariance Matrix Adaptation Evolutionary Strategy using observations including consumptions, inside temperatures and comfort measurements such as CO 2 emissions obtained with sensors displayed in the building. The temperatures inside the building and the energy consumptions predicted by the calibrated model during a new time period are then compared to the corresponding observations. The model is then used to find a set of Pareto optimal schedulings and tunings of the building management system in terms of energy loads and thermal comfort using multi-objective optimization.
    
  </div>

  <div class="pub-authors" itemprop="author">
    
    Le Corff, S., Champagne, A., Charbit, M., Noziere, G., Moulines, E
    
  </div>

  <div class="pub-publication">
    
    IEEE Data Science Workshop, p.41-45, EPFL, Lausanne,
    
    2018
  </div>

  <div class="pub-links">
    



<a class="btn btn-primary btn-outline btn-xs" href="https://www.researchgate.net/publication/327132787_OPTIMIZING_THERMAL_COMFORT_AND_ENERGY_CONSUMPTION_IN_A_LARGE_BUILDING_WITHOUT_RENOVATION_WORK" target="_blank" rel="noopener">
  Preprint
</a>














<a class="btn btn-primary btn-outline btn-xs" href="https://ieeexplore.ieee.org/document/8439901" target="_blank" rel="noopener">
  Source Document
</a>



  </div>

</div>

          
        </div>

        

        
          
        

        <div class="grid-sizer col-md-12 isotope-item pubtype-2 year-2018">
          
            <div class="pub-list-item card-simple" itemscope itemtype="http://schema.org/CreativeWork">

  
  

  <h3 class="article-title" itemprop="name">
    <a href="/publication/gloaguen_etienne_lecorff_2018/" itemprop="url">Stochastic differential equation based on a multimodal potential to model movement data in ecology</a>
  </h3>

  <div class="pub-abstract" itemprop="text">
    
    This paper proposes a new model for individuals movement in ecology. The movement process is defined as a solution to a stochastic differential equation whose drift is the gradient of a multimodal potential surface. This offers a new flexible approach among the popular potential based movement models in ecology. To perform parameter inference, the widely used Euler method is compared with two other pseudo-likelihood procedures and  with  a Monte Carlo Expectation Maximization approach based on exact simulation of diffusions . Performances of all methods are assessed with simulated data and with a data set of fishing vessels trajectories. We show that the usual Euler method performs worse than the other procedures for all sampling schemes.
    
  </div>

  <div class="pub-authors" itemprop="author">
    
    Gloaguen, P., Etienne, M.-P., Le Corff, S.
    
  </div>

  <div class="pub-publication">
    
    Journal of the Royal Statistical Society: Series C, Volume 67, Number 3, p. 599-616,
    
    2018
  </div>

  <div class="pub-links">
    



<a class="btn btn-primary btn-outline btn-xs" href="https://www.researchgate.net/publication/320631271_Stochastic_differential_equation_based_on_a_multimodal_potential_to_model_movement_data_in_ecology" target="_blank" rel="noopener">
  Preprint
</a>














<a class="btn btn-primary btn-outline btn-xs" href="https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/rssc.12251" target="_blank" rel="noopener">
  Source Document
</a>



  </div>

</div>

          
        </div>

        

        
          
        

        <div class="grid-sizer col-md-12 isotope-item pubtype-2 year-2018">
          
            <div class="pub-list-item card-simple" itemscope itemtype="http://schema.org/CreativeWork">

  
  

  <h3 class="article-title" itemprop="name">
    <a href="/publication/nguyen_lecorff_moulines_2018/" itemprop="url">On the two-filter approximations of marginal smoothing distributions in general state space models</a>
  </h3>

  <div class="pub-abstract" itemprop="text">
    
    A prevalent problem in general state-space models is the approximation of the smoothing distribution of a state conditional on the observations from the past, the present, and the future. The aim of this paper is to provide a rigorous analysis of such approximations of smoothed distributions provided by the two-filter algorithms. We extend the results available for the approximation of smoothing distributions to these two-filter approaches which combine a forward filter approximating the filtering distributions with a backward information filter approximating a quantity proportional to the posterior distribution of the state, given future observations.
    
  </div>

  <div class="pub-authors" itemprop="author">
    
    NGuyen, T.N.M., Le Corff, S., Moulines, E.
    
  </div>

  <div class="pub-publication">
    
    Advances in Applied Probability, Volume 50, Number 1, p. 154-177,
    
    2018
  </div>

  <div class="pub-links">
    



<a class="btn btn-primary btn-outline btn-xs" href="https://www.researchgate.net/publication/303656056_On_the_two-filter_approximations_of_marginal_smoothing_distributions_in_general_state_space_models" target="_blank" rel="noopener">
  Preprint
</a>














<a class="btn btn-primary btn-outline btn-xs" href="https://www.cambridge.org/core/journals/advances-in-applied-probability/article/on-the-twofilter-approximations-of-marginal-smoothing-distributions-in-general-statespace-models/712EEC6894348BED3FBE21B3DABF95A0" target="_blank" rel="noopener">
  Source Document
</a>



  </div>

</div>

          
        </div>

        

        
          
        

        <div class="grid-sizer col-md-12 isotope-item pubtype-2 year-2018">
          
            <div class="pub-list-item card-simple" itemscope itemtype="http://schema.org/CreativeWork">

  
  

  <h3 class="article-title" itemprop="name">
    <a href="/publication/gloaguen_etienne_lecorff_2018b/" itemprop="url">Online sequential Monte Carlo smoother for partially observed diffusion processes</a>
  </h3>

  <div class="pub-abstract" itemprop="text">
    
    This paper introduces a new algorithm to approximate smoothed additive functionals of partially observed diffusion processes. This method relies on a new sequential Monte Carlo method which allows to compute such approximations online, i.e., as the observations are received, and with a computational complexity growing linearly with the number of Monte Carlo samples. The original algorithm cannot be used in the case of partially observed stochastic differential equations since the transition density of the latent data is usually unknown. We prove that it may be extended to partially observed continuous processes by replacing this unknown quantity by an unbiased estimator obtained for instance using general Poisson estimators. This estimator is proved to be consistent and its performance are illustrated using data from two models.
    
  </div>

  <div class="pub-authors" itemprop="author">
    
    Gloaguen, P., Etienne, M.-P., Le Corff, S.
    
  </div>

  <div class="pub-publication">
    
    EURASIP Journal on Advances in Signal Processing, Volume 9,
    
    2018
  </div>

  <div class="pub-links">
    



<a class="btn btn-primary btn-outline btn-xs" href="https://www.researchgate.net/publication/322898743_Online_sequential_Monte_Carlo_smoother_for_partially_observed_diffusion_processes" target="_blank" rel="noopener">
  Preprint
</a>














<a class="btn btn-primary btn-outline btn-xs" href="https://asp-eurasipjournals.springeropen.com/articles/10.1186/s13634-018-0530-3" target="_blank" rel="noopener">
  Source Document
</a>



  </div>

</div>

          
        </div>

        

        
          
        

        <div class="grid-sizer col-md-12 isotope-item pubtype-2 year-2017">
          
            <div class="pub-list-item card-simple" itemscope itemtype="http://schema.org/CreativeWork">

  
  

  <h3 class="article-title" itemprop="name">
    <a href="/publication/nguyen_lecorff_moulines_2017/" itemprop="url">Particle rejuvenation of Rao-Blackwellized Sequential Monte Carlo smoothers for Conditionally Linear and Gaussian models</a>
  </h3>

  <div class="pub-abstract" itemprop="text">
    
    This paper focuses on sequential Monte Carlo approximations of smoothing distributions in conditionally linear and Gaussian state spaces. To reduce Monte Carlo variance of smoothers, it is typical in these models to use Rao-Blackwellization: particle approximation is used to sample sequences of hidden regimes while the Gaussian states are explicitly integrated conditional on the sequence of regimes and observations, using variants of the Kalman filter/smoother. The first successful attempt to use Rao-Blackwellization for smoothing extends the Bryson-Frazier smoother for Gaussian linear state space models using the generalized two-filter formula together with Kalman filters/smoothers. More recently, a forward-backward decomposition of smoothing distributions mimicking the Rauch-Tung-Striebel smoother for the regimes combined with backward Kalman updates has been introduced. This paper investigates the benefit of introducing additional rejuvenation steps in all these algorithms to sample at each time instant new regimes conditional on the forward and backward particles. This defines particle-based approximations of the smoothing distributions whose support is not restricted to the set of particles sampled in the forward or backward filter. These procedures are applied to commodity markets which are described using a two-factor model based on the spot price and a convenience yield for crude oil data.
    
  </div>

  <div class="pub-authors" itemprop="author">
    
    NGuyen, T.N.M., Le Corff, S., Moulines, E.
    
  </div>

  <div class="pub-publication">
    
    EURASIP Journal on Advances in Signal Processing, Volume 54,
    
    2017
  </div>

  <div class="pub-links">
    



<a class="btn btn-primary btn-outline btn-xs" href="https://www.researchgate.net/publication/318239446_Particle_rejuvenation_of_Rao-Blackwellized_Sequential_Monte_Carlo_smoothers_for_Conditionally_Linear_and_Gaussian_models" target="_blank" rel="noopener">
  Preprint
</a>














<a class="btn btn-primary btn-outline btn-xs" href="https://link.springer.com/article/10.1186/s13634-017-0489-5" target="_blank" rel="noopener">
  Source Document
</a>



  </div>

</div>

          
        </div>

        

        
          
        

        <div class="grid-sizer col-md-12 isotope-item pubtype-2 year-2017">
          
            <div class="pub-list-item card-simple" itemscope itemtype="http://schema.org/CreativeWork">

  
  

  <h3 class="article-title" itemprop="name">
    <a href="/publication/durmus_lecorff_moulines_roberts_2017/" itemprop="url">Optimal scaling of the Random Walk Metropolis algorithm under Lp mean differentiability</a>
  </h3>

  <div class="pub-abstract" itemprop="text">
    
    In this paper we consider the optimal scaling of high-dimensional random walk Metropolis algorithms for densities differentiable in the Lp mean but which may be irregular at some points (such as the Laplace density, for example) and/or supported on an interval. Our main result is the weak convergence of the Markov chain (appropriately rescaled in time and space) to a Langevin diffusion process as the dimension d goes to infinity. As the log-density might be nondifferentiable, the limiting diffusion could be singular. The scaling limit is established under assumptions which are much weaker than the one used in the original derivation of Roberts et al. (1997). This result has important practical implications for the use of random walk Metropolis algorithms in Bayesian frameworks based on sparsity inducing priors.
    
  </div>

  <div class="pub-authors" itemprop="author">
    
    Durmus, A., Le Corff, S., Moulines, E., Roberts, G.O.
    
  </div>

  <div class="pub-publication">
    
    Journal of Applied Probability, Volume 54, Number 4, p. 1233-1260,
    
    2017
  </div>

  <div class="pub-links">
    



<a class="btn btn-primary btn-outline btn-xs" href="https://arxiv.org/abs/1604.06664" target="_blank" rel="noopener">
  Preprint
</a>














<a class="btn btn-primary btn-outline btn-xs" href="https://www.cambridge.org/core/journals/journal-of-applied-probability/article/optimal-scaling-of-the-random-walk-metropolis-algorithm-under-l-p-mean-differentiability/53894E10E1CE92715CFA6C29FD503747" target="_blank" rel="noopener">
  Source Document
</a>



  </div>

</div>

          
        </div>

        

        
          
        

        <div class="grid-sizer col-md-12 isotope-item pubtype-2 year-2017">
          
            <div class="pub-list-item card-simple" itemscope itemtype="http://schema.org/CreativeWork">

  
  

  <h3 class="article-title" itemprop="name">
    <a href="/publication/dahlhaus_dumont_lecorff_neddermeyer_2017/" itemprop="url">Statistical inference for oscillation processes</a>
  </h3>

  <div class="pub-abstract" itemprop="text">
    
    A new model for time series with a specific oscillation pattern is proposed. The model consists of a hidden phase process controlling the speed of polling and a nonparametric curve characterizing the pattern, leading together to a generalized state space model. Identifiability of the model is proved and a method for statistical inference based on a particle smoother and a nonparametric EM algorithm is developed. In particular, the oscillation pattern and the unobserved phase process are estimated. The proposed algorithms are computationally efficient and their performance is assessed through simulations and an application to human electrocardiogram recordings.
    
  </div>

  <div class="pub-authors" itemprop="author">
    
    Dahlhaus, R., Dumont, T., Le Corff, S., Neddermeyer, J.C.
    
  </div>

  <div class="pub-publication">
    
    Statistics, Volume 51, Number 1, p.61-83,
    
    2017
  </div>

  <div class="pub-links">
    



<a class="btn btn-primary btn-outline btn-xs" href="https://www.researchgate.net/publication/278619556_Statistical_Inference_for_Oscillation_Processes" target="_blank" rel="noopener">
  Preprint
</a>














<a class="btn btn-primary btn-outline btn-xs" href="https://www.tandfonline.com/doi/full/10.1080/02331888.2016.1266985" target="_blank" rel="noopener">
  Source Document
</a>



  </div>

</div>

          
        </div>

        

        
          
        

        <div class="grid-sizer col-md-12 isotope-item pubtype-2 year-2017">
          
            <div class="pub-list-item card-simple" itemscope itemtype="http://schema.org/CreativeWork">

  
  

  <h3 class="article-title" itemprop="name">
    <a href="/publication/dumont_lecorff_2017/" itemprop="url">Nonparametric regression on hidden phi-mixing variables: identifiability and consistency of a pseudo-likelihood based estimation procedure</a>
  </h3>

  <div class="pub-abstract" itemprop="text">
    
    This paper outlines a new nonparametric estimation procedure for unobserved phi-mixing processes. It is assumed that the only information on the stationary hidden states Xk is given by the process Yk, where Yk is a noisy observation of f(Xk). The paper introduces a maximum pseudo-likelihood procedure to estimate the function f and the distribution vb of the first b states using blocks of observations of length b. The identifiability of the model is studied in the particular cases b = 1 and b = 2 and the consistency of the estimators of f and of vb, as the number of observations grows to infinity is established.
    
  </div>

  <div class="pub-authors" itemprop="author">
    
    Dumont, T., Le Corff, S.
    
  </div>

  <div class="pub-publication">
    
    Bernoulli, Volume 23, Number 2, p.990-1021,
    
    2017
  </div>

  <div class="pub-links">
    



<a class="btn btn-primary btn-outline btn-xs" href="https://www.researchgate.net/publication/277116783_Nonparametric_Regression_on_Hidden_Phi-Mixing_Variables_Identifiability_and_Consistency_of_a_Pseudo-Likelihood_Based_Estimation_Procedure" target="_blank" rel="noopener">
  Preprint
</a>














<a class="btn btn-primary btn-outline btn-xs" href="https://projecteuclid.org/euclid.bj/1486177390" target="_blank" rel="noopener">
  Source Document
</a>



  </div>

</div>

          
        </div>

        

        
          
        

        <div class="grid-sizer col-md-12 isotope-item pubtype-2 year-2017">
          
            <div class="pub-list-item card-simple" itemscope itemtype="http://schema.org/CreativeWork">

  
  

  <h3 class="article-title" itemprop="name">
    <a href="/publication/decastro_gassiat_lecorff_2017/" itemprop="url">Consistent estimation of the filtering and marginal smoothing distributions in nonparametric hidden Markov models</a>
  </h3>

  <div class="pub-abstract" itemprop="text">
    
    In this paper, we consider the filtering and smoothing recursions in nonparametric finite state space hidden Markov models (HMMs) when the parameters of the model are unknown and replaced by estimators. We provide an explicit and time uniform control of the filtering and smoothing errors in total variation norm as a function of the parameter estimation errors. We prove that the risk for the filtering and smoothing errors may be uniformly upper bounded by the L1-risk of the estimators. It has been proved very recently that statistical inference for finite state space nonparametric HMMs is possible. We study how the recent spectral methods developed in the parametric setting may be extended to the nonparametric framework and we give explicit upper bounds for the L2-risk of the nonparametric spectral estimators. In the case where the observation space is compact, this provides explicit rates for the filtering and smoothing errors in total variation norm. The performance of the spectral method is assessed with simulated data for both the estimation of the (nonparametric) conditional distribution of the observations and the estimation of the marginal smoothing distributions.
    
  </div>

  <div class="pub-authors" itemprop="author">
    
    de Castro, Y., Gassiat, E., Le Corff, S.
    
  </div>

  <div class="pub-publication">
    
    IEEE Transactions on Information Theory, volume 63, Number 8, p. 4758-4777,
    
    2017
  </div>

  <div class="pub-links">
    



<a class="btn btn-primary btn-outline btn-xs" href="https://www.researchgate.net/publication/280329728_Consistent_Estimation_of_the_Filtering_and_Marginal_Smoothing_Distributions_in_Nonparametric_Hidden_Markov_Models" target="_blank" rel="noopener">
  Preprint
</a>














<a class="btn btn-primary btn-outline btn-xs" href="https://ieeexplore.ieee.org/document/7907196/" target="_blank" rel="noopener">
  Source Document
</a>



  </div>

</div>

          
        </div>

        

        
          
        

        <div class="grid-sizer col-md-12 isotope-item pubtype-2 year-2015">
          
            <div class="pub-list-item card-simple" itemscope itemtype="http://schema.org/CreativeWork">

  
  

  <h3 class="article-title" itemprop="name">
    <a href="/publication/schreck_fort_lecorff_moulines_2015/" itemprop="url">A shrinkage-thresholding Metropolis adjusted Langevin algorithm for Bayesian variable selection</a>
  </h3>

  <div class="pub-abstract" itemprop="text">
    
    This paper introduces a new Markov Chain Monte Carlo method for Bayesian variable selection in high dimensional settings. The algorithm is a Hastings-Metropolis sampler with a proposal mechanism which combines a Metropolis Adjusted Langevin (MALA) step to propose local moves associated with a shrinkage-thresholding step allowing to propose new models. The geometric ergodicity of this new trans-dimensional Markov Chain Monte Carlo sampler is established. An extensive numerical experiment, on simulated and real data, is presented to illustrate the performance of the proposed algorithm in comparison with some more classical trans-dimensional algorithms.
    
  </div>

  <div class="pub-authors" itemprop="author">
    
    Schreck, A., Fort, G., Le Corff, S., Moulines, E.
    
  </div>

  <div class="pub-publication">
    
    IEEE Journal of Selected Topics in Signal Processing, Volume 10, p.366-375,
    
    2015
  </div>

  <div class="pub-links">
    



<a class="btn btn-primary btn-outline btn-xs" href="https://www.researchgate.net/publication/259367918_A_Shrinkage-Thresholding_Metropolis_Adjusted_Langevin_Algorithm_for_Bayesian_Variable_Selection" target="_blank" rel="noopener">
  Preprint
</a>














<a class="btn btn-primary btn-outline btn-xs" href="https://ieeexplore.ieee.org/document/7312917/" target="_blank" rel="noopener">
  Source Document
</a>



  </div>

</div>

          
        </div>

        

        
          
        

        <div class="grid-sizer col-md-12 isotope-item pubtype-2 year-2014">
          
            <div class="pub-list-item card-simple" itemscope itemtype="http://schema.org/CreativeWork">

  
  

  <h3 class="article-title" itemprop="name">
    <a href="/publication/dumont_lecorff_2014/" itemprop="url">Simultaneous localization and mapping problem in wireless sensor networks</a>
  </h3>

  <div class="pub-abstract" itemprop="text">
    
    Mobile device localization in wireless sensor networks is a challenging task. It has already been addressed when the WiFi propagation maps of the access points are modeled deterministically or estimated using an offline human training calibration. However, these techniques do not take into account the environmental dynamics. In this paper, the maps are assumed to be made of an average indoor propagation model combined with a perturbation field which represents the influence of the environment. This perturbation field is embedded with a distribution describing the prior knowledge about the environmental influence. The device is localized with Sequential Monte Carlo methods and relies on the estimation of the propagation maps. This inference task is performed online, using the observations sequentially, with a new online Expectation Maximization based algorithm. The performance of the algorithm is illustrated with Monte Carlo experiments using both simulated data and a true data set.
    
  </div>

  <div class="pub-authors" itemprop="author">
    
    Dumont, T., Le Corff, S.
    
  </div>

  <div class="pub-publication">
    
    Signal Processing, Volume 101, p.192-203,
    
    2014
  </div>

  <div class="pub-links">
    



<a class="btn btn-primary btn-outline btn-xs" href="https://www.researchgate.net/publication/258727749_Simultaneous_Localization_and_Mapping_Problem_in_Wireless_Sensor_Networks" target="_blank" rel="noopener">
  Preprint
</a>














<a class="btn btn-primary btn-outline btn-xs" href="https://www.sciencedirect.com/science/article/pii/S0165168414000814" target="_blank" rel="noopener">
  Source Document
</a>



  </div>

</div>

          
        </div>

        

        
          
        

        <div class="grid-sizer col-md-12 isotope-item pubtype-2 year-2013">
          
            <div class="pub-list-item card-simple" itemscope itemtype="http://schema.org/CreativeWork">

  
  

  <h3 class="article-title" itemprop="name">
    <a href="/publication/lecorff_fort_2013/" itemprop="url">Online Expectation Maximization based algorithms for inference in hidden Markov models</a>
  </h3>

  <div class="pub-abstract" itemprop="text">
    
    The Expectation Maximization (EM) algorithm is a versatile tool for model parameter estimation in latent data models. When processing large data sets or data stream however, EM becomes intractable since it requires the whole data set to be available at each iteration of the algorithm. In this contribution, a new generic online EM algorithm for model parameter inference in general Hidden Markov Model is proposed. This new algorithm updates the parameter estimate after a block of observations is processed (online). The convergence of this new algorithm is established, and the rate of convergence is studied showing the impact of the block-size sequence. An averaging procedure is also proposed to improve the rate of convergence. Finally, practical illustrations are presented to highlight the performance of these algorithms in comparison to other online maximum likelihood procedures.
    
  </div>

  <div class="pub-authors" itemprop="author">
    
    Le Corff, S., Fort, G.
    
  </div>

  <div class="pub-publication">
    
    Electronic Journal of Statistics (EJS), Volume 7, Number 5B, p.763-792,
    
    2013
  </div>

  <div class="pub-links">
    



<a class="btn btn-primary btn-outline btn-xs" href="https://arxiv.org/abs/1108.3968" target="_blank" rel="noopener">
  Preprint
</a>














<a class="btn btn-primary btn-outline btn-xs" href="https://projecteuclid.org/euclid.ejs/1364220670" target="_blank" rel="noopener">
  Source Document
</a>



  </div>

</div>

          
        </div>

        

        
          
        

        <div class="grid-sizer col-md-12 isotope-item pubtype-1 year-2013">
          
            <div class="pub-list-item card-simple" itemscope itemtype="http://schema.org/CreativeWork">

  
  

  <h3 class="article-title" itemprop="name">
    <a href="/publication/dumont_lecorff_2013/" itemprop="url">Online EM for indoor simultaneous localization and mapping</a>
  </h3>

  <div class="pub-abstract" itemprop="text">
    
    This paper addresses the problem of mobile device localization in wireless sensor networks. The mobile is assumed to receive the signals transmitted byWiFi access points. The localization procedure is performed online (i.e. using the observations acquired by the mobile) and relies on the estimation of the propagation maps of the signal associated with each access point. This intermediate estimation step uses a new online Expectation Maximization based algorithm and Sequential Monte Carlo methods.
    
  </div>

  <div class="pub-authors" itemprop="author">
    
    Dumont, T., Le Corff, S
    
  </div>

  <div class="pub-publication">
    
    Proceedings of the 38th International Conference on Acoustics, Speech, and Signal Processing (ICASSP), p.6431-6435,
    
    2013
  </div>

  <div class="pub-links">
    



<a class="btn btn-primary btn-outline btn-xs" href="https://www.researchgate.net/publication/261333347_Online_EM_for_indoor_simultaneous_localization_and_mapping" target="_blank" rel="noopener">
  Preprint
</a>














<a class="btn btn-primary btn-outline btn-xs" href="https://ieeexplore.ieee.org/document/6638904" target="_blank" rel="noopener">
  Source Document
</a>



  </div>

</div>

          
        </div>

        

        
          
        

        <div class="grid-sizer col-md-12 isotope-item pubtype-2 year-2013">
          
            <div class="pub-list-item card-simple" itemscope itemtype="http://schema.org/CreativeWork">

  
  

  <h3 class="article-title" itemprop="name">
    <a href="/publication/dubarry_lecorff_2013/" itemprop="url">Nonasymptotic deviation inequalities for smoothed additive functionals in nonlinear state-space models with applications to parameter estimation</a>
  </h3>

  <div class="pub-abstract" itemprop="text">
    
    The approximation of fixed-interval smoothing distributions is a key issue in inference for general state-space hidden Markov models (HMM). This contribution establishes non-asymptotic bounds for the Forward Filtering Backward Smoothing (FFBS) and the Forward Filtering Backward Simulation (FFBSi) estimators of fixed-interval smoothing functionals. We show that the rate of convergence of the Lq-mean errors of both methods depends on the number of observations T and the number of particles N only through the ratio T/N for additive functionals. In the case of the FFBS, this improves recent results providing bounds depending on T and the square root of N.
    
  </div>

  <div class="pub-authors" itemprop="author">
    
    Dubarry, C., Le Corff, S.
    
  </div>

  <div class="pub-publication">
    
    Bernoulli, Volume 19, Number 5B, p.2222-2249,
    
    2013
  </div>

  <div class="pub-links">
    



<a class="btn btn-primary btn-outline btn-xs" href="https://arxiv.org/abs/1012.4183" target="_blank" rel="noopener">
  Preprint
</a>














<a class="btn btn-primary btn-outline btn-xs" href="https://projecteuclid.org/euclid.bj/1386078601" target="_blank" rel="noopener">
  Source Document
</a>



  </div>

</div>

          
        </div>

        

        
          
        

        <div class="grid-sizer col-md-12 isotope-item pubtype-1 year-2013">
          
            <div class="pub-list-item card-simple" itemscope itemtype="http://schema.org/CreativeWork">

  
  

  <h3 class="article-title" itemprop="name">
    <a href="/publication/lecorff_fort_moulines_2013/" itemprop="url">New Online EM algorithms for general hidden Markov models. Application to the SLAM problem</a>
  </h3>

  <div class="pub-abstract" itemprop="text">
    
    In this contribution, new online EM algorithms are proposed to perform inference in general hidden Markov models. These algorithms update the parameter at some deterministic times and use Sequential Monte Carlo methods to compute approximations of filtering distributions. In this paper, the performance of these algorithms are highlighted in the challenging framework of Simultaneous Localization and Mapping.
    
  </div>

  <div class="pub-authors" itemprop="author">
    
    Le Corff, S., Fort, G., Moulines, E.
    
  </div>

  <div class="pub-publication">
    
    Proceedings of the 10th International Conference on Latent Variable Analysis and Signal Separation (LVA/ICA), p.131-138,
    
    2013
  </div>

  <div class="pub-links">
    
















<a class="btn btn-primary btn-outline btn-xs" href="https://dl.acm.org/citation.cfm?id=2187321.2187339" target="_blank" rel="noopener">
  Source Document
</a>



  </div>

</div>

          
        </div>

        

        
          
        

        <div class="grid-sizer col-md-12 isotope-item pubtype-2 year-2013">
          
            <div class="pub-list-item card-simple" itemscope itemtype="http://schema.org/CreativeWork">

  
  

  <h3 class="article-title" itemprop="name">
    <a href="/publication/lecorff_fort_2013b/" itemprop="url">Convergence of a Particle-based Approximation of the Block Online Expectation Maximization Algorithm</a>
  </h3>

  <div class="pub-abstract" itemprop="text">
    
    Online variants of the Expectation Maximization (EM) algorithm have recently been proposed to perform parameter inference with large data sets or data streams, in independent latent models and in hidden Markov models. Nevertheless, the convergence properties of these algorithms remain an open problem at least in the hidden Markov case. This contribution deals with a new online EM algorithm that updates the parameter at some deterministic times. Some convergence results have been derived even in general latent models such as hidden Markov models. These properties rely on the assumption that some intermediate quantities are available in closed form or can be approximated by Monte Carlo methods when the Monte Carlo error vanishes rapidly enough. In this article, we propose an algorithm that approximates these quantities using Sequential Monte Carlo methods. The convergence of this algorithm and of an averaged version is established and their performance is illustrated through Monte Carlo experiments.
    
  </div>

  <div class="pub-authors" itemprop="author">
    
    Le Corff, S., Fort, G.
    
  </div>

  <div class="pub-publication">
    
    ACM: Transactions on Modeling and Computer Simulation, Special Issue on Monte Carlo Methods in Statistics, Volume 23-1, p.1-22,
    
    2013
  </div>

  <div class="pub-links">
    



<a class="btn btn-primary btn-outline btn-xs" href="https://arxiv.org/abs/1111.1307" target="_blank" rel="noopener">
  Preprint
</a>














<a class="btn btn-primary btn-outline btn-xs" href="https://dl.acm.org/citation.cfm?doid=2414416.2414418" target="_blank" rel="noopener">
  Source Document
</a>



  </div>

</div>

          
        </div>

        

        
          
        

        <div class="grid-sizer col-md-12 isotope-item pubtype-1 year-2011">
          
            <div class="pub-list-item card-simple" itemscope itemtype="http://schema.org/CreativeWork">

  
  

  <h3 class="article-title" itemprop="name">
    <a href="/publication/lecorff_fort_moulines_2011/" itemprop="url">Online Expectation Maximization based algorithms for inference in hidden Markov models</a>
  </h3>

  <div class="pub-abstract" itemprop="text">
    
    In this paper, a new algorithm - namely the onlineEM-SLAM - is proposed to solve the simultaneous localization and mapping problem (SLAM). The mapping problem is seen as an instance of inference in latent models, and the localization part is dealt with a particle approximation method. This new technique relies on an online version of the Expectation Maximization (EM) algorithm: the algorithm includes a stochastic approximation version of the E-step to incorporate the information brought by the newly available observation. By linearizing the observation model, the stochastic approximation part is reduced to the computation of the expectation of additive functionals of the robot pose. Therefore, each iteration of the onlineEM-SLAM both provides a particle approximation of the distribution of the pose, and a point estimate of the map. This online variant of EM does not require the whole data set to be available at each iteration. The performance of this algorithm is illustrated through simulations using sampled observations and experimental data.
    
  </div>

  <div class="pub-authors" itemprop="author">
    
    Le Corff, S., Fort, G., Moulines, E.
    
  </div>

  <div class="pub-publication">
    
    IEEE Workshop on Statistical Signal Processing (SSP), p.225-228,
    
    2011
  </div>

  <div class="pub-links">
    
















<a class="btn btn-primary btn-outline btn-xs" href="https://ieeexplore.ieee.org/document/5967666" target="_blank" rel="noopener">
  Source Document
</a>



  </div>

</div>

          
        </div>

        

        
          
        

        <div class="grid-sizer col-md-12 isotope-item pubtype-1 year-2011">
          
            <div class="pub-list-item card-simple" itemscope itemtype="http://schema.org/CreativeWork">

  
  

  <h3 class="article-title" itemprop="name">
    <a href="/publication/dubarry_lecorff_2011/" itemprop="url">Fast computation of smoothed additive functionals in general state-space models</a>
  </h3>

  <div class="pub-abstract" itemprop="text">
    
    Approximating fixed-interval smoothing distributions using particle-based methods is a well-known issue in statistical inference when operating on general state-space hidden Markov models (HMM). In this paper we focus on the computation of path-space smoothed additive functionals. More precisely, this contribution provides new results on the forward filtering backward smoothing (FFBS) and the forward filtering backward simulation (FFBSi) algorithms. We prove that the Lq-mean error convergence rate of both algorithms depends on the number of observations T and the number of particles N only through the ratio T/N. We also derive non-asymptotic exponential deviation inequalities for these algorithms. The FFBS and FFBSi algorithms are compared when applied to parameter estimation in HMM.
    
  </div>

  <div class="pub-authors" itemprop="author">
    
    Dubarry, C., Le Corff, S
    
  </div>

  <div class="pub-publication">
    
    IEEE Workshop on Statistical Signal Processing (SSP), p.197-200,
    
    2011
  </div>

  <div class="pub-links">
    
















<a class="btn btn-primary btn-outline btn-xs" href="https://ieeexplore.ieee.org/document/5967657" target="_blank" rel="noopener">
  Source Document
</a>



  </div>

</div>

          
        </div>

        
      </div>

    </div>
  </div>
</div>
<footer class="site-footer">
  <div class="container">

    
    <p class="powered-by">
      <a href="/privacy/">Privacy Policy</a>
    </p>
    

    <p class="powered-by">

      &copy; 2018 &middot; 

      Powered by the
      <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
      <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

      <span class="pull-right" aria-hidden="true">
        <a href="#" id="back_to_top">
          <span class="button_icon">
            <i class="fa fa-chevron-up fa-2x"></i>
          </span>
        </a>
      </span>

    </p>
  </div>
</footer>


<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <button type="button" class="close btn-large" data-dismiss="modal">&times;</button>
        <h4 class="modal-title">Cite</h4>
      </div>
      <div>
        <pre><code class="modal-body tex"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-primary btn-outline js-copy-cite" href="#" target="_blank">
          <i class="fa fa-copy"></i> Copy
        </a>
        <a class="btn btn-primary btn-outline js-download-cite" href="#" target="_blank">
          <i class="fa fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

    

    
    

    

    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.2.1/jquery.min.js" integrity="sha512-3P8rXCuGJdNZOnUx/03c1jOTnMn3rP63nBip5gOP2qmUh5YAdVAvFZ1E+QLZZbC1rtMrQb+mah3AfYW11RUrWA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.3/imagesloaded.pkgd.min.js" integrity="sha512-umsR78NN0D23AzgoZ11K7raBD+R6hqKojyBZs1w8WvYlsI+QuKRGBx3LFCwhatzBunCjDuJpDHwxD13sLMbpRA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha512-iztkobsvnjKfAtTNdHkGVjAYTrrtlC7mGp/54c40wowO7LhURYl3gVzzcEqGl/qKXQltJ2HwMrdLcNUdo+N/RQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>
    
    
    <script src="/js/hugo-academic.js"></script>
    

    
    

    
    
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        CommonHTML: { linebreaks: { automatic: true } },
        tex2jax: { inlineMath: [ ['$', '$'], ['\\(','\\)'] ], displayMath: [ ['$$','$$'], ['\\[', '\\]'] ], processEscapes: false },
        TeX: { noUndefined: { attributes: { mathcolor: 'red', mathbackground: '#FFEEEE', mathsize: '90%' } } },
        messageStyle: 'none'
      });
    </script>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_CHTML-full" integrity="sha256-GhM+5JHb6QUzOQPXSJLEWP7R73CbkisjzK5Eyij4U9w=" crossorigin="anonymous"></script>
    
    

    
    

  </body>
</html>

